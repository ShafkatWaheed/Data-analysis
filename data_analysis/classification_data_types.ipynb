{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lda\n",
    "\n",
    "from data_analysis.topic_tokenizer import TopicTokenizer\n",
    "from data_analysis._util import make_document_term_matrix\n",
    "\n",
    "\n",
    "file_ = 'twitter.sqlite3'\n",
    "tweets = pd.read_sql_table('tweets', 'sqlite:///{}'.format(file_))\n",
    "tweets = tweets[tweets.is_retweet == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TopicTokenizer()\n",
    "token_list = [tokenizer.tokenize(t) for t in tweets.tweet[0:2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer.tokenize('@benhoff https://www.googel.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_list = [t for t in token_list if t]\n",
    "bool([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_matrix, vocabulary = make_document_term_matrix(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = lda.LDA(n_topics=120, n_iter=1500, random_state=1)\n",
    "model.fit(document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_array = np.array(list(vocabulary.keys()))\n",
    "for i, topic_dist in enumerate(model.topic_word_):\n",
    "    temp = np.argpartition(-topic_dist, 8)\n",
    "    result = temp[:8]\n",
    "    word_result = []\n",
    "    for r in result:\n",
    "        word_result.append(vocab_array[r])\n",
    "    print('Topic {}: {}'.format(i, ' '.join(word_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classified_data = model.fit_transform(document_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classified_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# classified_data = classified_data.argmax(1)\n",
    "from collections import Counter\n",
    "count = Counter(classified_data)\n",
    "keys_counts = np.array(count.most_common())\n",
    "keys = keys_counts[:, 0]\n",
    "counts = keys_counts[:, 1]\n",
    "print(keys, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.barh(np.arange(len(counts), 0, -1), counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocabulary_helper(topic_numbers, number=5):\n",
    "    vocab = np.array(list(vocabulary.keys()))\n",
    "    topic_models = model.topic_word_\n",
    "    result = []\n",
    "    for topic_number in topic_numbers:\n",
    "        words = vocab[np.argsort(topic_models[topic_number])][:-(number+1):-1]\n",
    "        result.append(words)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = get_vocabulary_helper(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(111)\n",
    "X, Y = fig.get_dpi() * fig.get_size_inches()\n",
    "h = Y / (20)\n",
    "\n",
    "for row, words in enumerate(word_list):\n",
    "    y = Y - (row * h) - h\n",
    "\n",
    "    axis.text(0.3, y, ' '.join(words), fontsize=(h * 0.8),\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='center')\n",
    "\n",
    "axis.set_ylim(0, Y)\n",
    "axis.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(111)\n",
    "X, Y = fig.get_dpi() * fig.get_size_inches()\n",
    "num_print = 10\n",
    "h = Y / num_print\n",
    "\n",
    "y_s = []\n",
    "for row, words in enumerate(word_list[:num_print]):\n",
    "    y = Y - (row * h) - h\n",
    "    y_s.append(y)\n",
    "    axis.text(1, y, ' '.join(words), fontsize=(h*.5),\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='center',\n",
    "             color='gold')\n",
    "y_s[-1] = 0\n",
    "axis.set_ylim(-20, Y)\n",
    "#axis.set_xlin(0, )\n",
    "axis.barh(y_s, counts[:num_print], height=30, color='midnightblue')\n",
    "axis.get_yaxis().set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
